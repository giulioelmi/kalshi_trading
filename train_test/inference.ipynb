{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9aed3c-a4c0-4a7c-9c91-10ed3d4327e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8afc28-3d2f-4c77-92ee-d68d5d85a32f",
   "metadata": {},
   "source": [
    "Get data from the last 50 climatoligical reports that are about yesterday and keep only the latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42aac61-b48b-4d25-bf01-8e4f4ececcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_text(v):\n",
    "    URL = f\"https://forecast.weather.gov/product.php?site=LOX&issuedby=LAX&product=CLI&format=TXT&version={v}&glossary=0\"\n",
    "    r = requests.get(URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def normalize_cli_text(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"[ \\t]+\\n\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_cli_yesterday(version = 50):\n",
    "    rows = []  \n",
    "    patterns = {\n",
    "        \"DATE\": r\"CA CLIMATE SUMMARY FOR (\\w+ \\d{1,2} \\d{4})\",\n",
    "        \"TMAX\": r\"YESTERDAY\\s+MAXIMUM\\s+(\\d+)\",\n",
    "        \"TMIN\": r\"MINIMUM\\s+(\\d+)\",\n",
    "        \"PRCP\": r\"PRECIPITATION\\s*\\(IN\\)\\s*YESTERDAY\\s+([0-9]+(?:\\.[0-9]+)?)\",\n",
    "        \"AWND\": r\"AVERAGE WIND SPEED\\s+([\\d.]+)\",\n",
    "        \"WDF2\": r\"HIGHEST WIND DIRECTION\\s+\\w+\\s+\\((\\d+)\\)\",\n",
    "        \"WSF2\": r\"HIGHEST WIND SPEED\\s+(\\d+)\"\n",
    "    }\n",
    "    #changed version for testing\n",
    "    for n in range(1, version):\n",
    "        text = normalize_cli_text(get_text(n))\n",
    "\n",
    "        # Match object or None\n",
    "        valid_yesterday = re.search(r\"YESTERDAY\", text)\n",
    "        if not valid_yesterday:\n",
    "            print(f\"no report available for version {n}\")\n",
    "            continue\n",
    "        print(\"downloading report\")\n",
    "\n",
    "        out = {}\n",
    "        for k, p in patterns.items():\n",
    "            m = re.search(p, text, flags=re.MULTILINE | re.DOTALL)\n",
    "            out[k] = m.group(1) if m else None\n",
    "        rows.append(out)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format = \"mixed\")\n",
    "    for c in [\"TMAX\", \"TMIN\", \"WSF2\", \"WDF2\", \"PRCP\", \"AWND\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df.drop_duplicates(subset = [\"DATE\"], keep = \"first\", inplace = True)\n",
    "    return df\n",
    "\n",
    "#changed version for testing\n",
    "def extract_cli_today(version = 1):\n",
    "    rows_today = []  \n",
    "    patterns = {\n",
    "        \"DATE\": r\"CA CLIMATE SUMMARY FOR (\\w+ \\d{1,2} \\d{4})\",\n",
    "        \"TMAX\": r\"TODAY\\s+MAXIMUM\\s+(\\d+)\",\n",
    "        \"TMIN\": r\"MINIMUM\\s+(\\d+)\",\n",
    "        \"PRCP\": r\"PRECIPITATION\\s*\\(IN\\)\\s*TODAY\\s+([0-9]+(?:\\.[0-9]+)?)\",\n",
    "        \"AWND\": r\"AVERAGE WIND SPEED\\s+([\\d.]+)\",\n",
    "        \"WDF2\": r\"HIGHEST WIND DIRECTION\\s+\\w+\\s+\\((\\d+)\\)\",\n",
    "        \"WSF2\": r\"HIGHEST WIND SPEED\\s+(\\d+)\"\n",
    "        ,\n",
    "    }\n",
    "    text = normalize_cli_text(get_text(version))\n",
    "    valid_today = re.search(r\"TEMPERATURE\\s*\\(F\\)[\\s\\S]*?\\bTODAY\\b\", text)\n",
    "    if not valid_today:\n",
    "        print(\"no report available for today\")\n",
    "        return None\n",
    "    print(\"downloading report\")   \n",
    "    out = {}\n",
    "    for k, p in patterns.items():\n",
    "        m = re.search(p, text, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL)\n",
    "        out[k] = m.group(1) if m else None\n",
    "    df = pd.DataFrame([out])  # one row\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], errors=\"coerce\")\n",
    "    for c in [\"TMAX\", \"TMIN\", \"WSF2\", \"WDF2\", \"PRCP\", \"AWND\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d8c9f-b219-4b0c-a098-224e5ab1b6d9",
   "metadata": {},
   "source": [
    "extract the forecasted max temp for tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d163d528-f90f-4af6-962c-711a68c84d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime as dt\n",
    "\n",
    "#changed date for testing: subtracted 1 day from today\n",
    "def get_forecast():\n",
    "    print(\"fetching forecast\")\n",
    "    LAT, LON = 33.94, -118.401\n",
    "    HEADERS = {\"User-Agent\": \"giulio\"}\n",
    "    URL = \"https://api.weather.gov/gridpoints/LOX/149,41/forecast/hourly\"\n",
    "    tomorrow = (dt.date.today() + dt.timedelta(days=1)).isoformat()\n",
    "    today = dt.date.today().isoformat()\n",
    "    r = requests.get(URL, headers=HEADERS)\n",
    "    periods = r.json()[\"properties\"][\"periods\"]\n",
    "    tmax = -999\n",
    "    \n",
    "    for p in periods:\n",
    "        if p[\"startTime\"][:10] == tomorrow:\n",
    "            tmax = max(tmax, p[\"temperature\"])\n",
    "    if tmax == -999:\n",
    "        print(\"cannot fetch forecast\")\n",
    "    else: print(\"forecast downloaded\")\n",
    "    max_temp_today = {\"DATE\": today, \"forecasted_TMAX\": tmax}\n",
    "    df = pd.DataFrame([max_temp_today])\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format = \"mixed\")\n",
    "    df[\"forecasted_TMAX\"] = pd.to_numeric(df[\"forecasted_TMAX\"], errors = \"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18494d1-b55b-4aa2-8bb5-3a6764d669dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    df_yesterday = extract_cli_yesterday()\n",
    "    df_today = extract_cli_today()\n",
    "    df_forecast = get_forecast()\n",
    "    df_merged = pd.concat([df_yesterday, df_today], axis=0)\n",
    "    df_merged[\"year\"] = df_merged[\"DATE\"].dt.year\n",
    "    df_inference = pd.merge(df_merged, df_forecast, how = \"left\", on = \"DATE\")\n",
    "    df_inference = df_inference.sort_values(\"DATE\", ascending=False)\n",
    "    print(df_inference.head(8))\n",
    "    return df_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f789897-b608-421a-ac3c-8f5952e34113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def feature_engineering(df):\n",
    "    print(\"starting feature engineering\")\n",
    "    df = df\n",
    "    df = df.sort_values(\"DATE\").reset_index(drop=True)\n",
    "    cols_to_ffill = [\"DATE\", \"TMAX\", \"TMIN\", \"PRCP\", \"AWND\", \"WSF2\", \"WDF2\", \"forecasted_TMAX\"]\n",
    "    df[cols_to_ffill] = df[cols_to_ffill].ffill()\n",
    "\n",
    "    df[\"doy\"] = df[\"DATE\"].dt.dayofyear\n",
    "    df[\"dow\"] = df[\"DATE\"].dt.dayofweek\n",
    "    df[\"month\"] = df[\"DATE\"].dt.month\n",
    "    df[\"doy_sin\"] = np.sin(2*np.pi*df[\"doy\"]/365.25)\n",
    "    df[\"doy_cos\"] = np.cos(2*np.pi*df[\"doy\"]/365.25)\n",
    "    \n",
    "    df[\"diurnal_range\"] = df[\"TMAX\"] - df[\"TMIN\"]\n",
    "    df[\"wind_dir_sin\"] = np.sin(np.deg2rad(df[\"WDF2\"]))\n",
    "    df[\"wind_dir_cos\"] = np.cos(np.deg2rad(df[\"WDF2\"]))\n",
    "    \n",
    "    #lags\n",
    "    lag_cols_1 = [\"TMAX\", \"TMIN\", \"diurnal_range\"]\n",
    "    for c in lag_cols_1:\n",
    "        for k in [1, 2, 3, 7]:\n",
    "            df[f\"{c}_lag{k}\"] = df[c].shift(k)\n",
    "    lag_cols_2 = [\"PRCP\"]\n",
    "    for k in [1, 2, 3, 4]:\n",
    "        df[f\"PRCP_lag_{k}\"] = df[\"PRCP\"].shift(k)\n",
    "\n",
    "    #rolling means \n",
    "    df[\"rolling_3\"] = df[\"TMAX\"].rolling(3).mean()\n",
    "    df[\"rolling_7\"] = df[\"TMAX\"].rolling(7).mean()\n",
    "    df = df.sort_values(\"DATE\", ascending = False).reset_index(drop=True)\n",
    "    df = df.iloc[:1]\n",
    "    df = df.drop(columns = [\"DATE\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8fe79b-734b-455e-a6f8-49cc2a1ae8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def make_prediction(df):\n",
    "    inference_df = df\n",
    "    model = XGBRegressor()\n",
    "    model.load_model(\"/Users/giulioelmi/Desktop/kelshi_trading/inference/best1.1.json\")\n",
    "    pred_error = float(model.predict(inference_df)[0])\n",
    "    forecast = df[\"forecasted_TMAX\"].iloc[0]\n",
    "    adjusted_forecast = forecast  + pred_error\n",
    "    print(\"------------------\")\n",
    "    print(\"Predicted error (TMAX_obs - TMAX_forecast):\", pred_error)\n",
    "    print(\"Forecast: \", forecast)\n",
    "    print(\"Adjusted forecast: \", adjusted_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74df630f-79d9-48ff-bfc8-daaf2d9b9b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no report available for version 1\n",
      "downloading report\n",
      "no report available for version 3\n",
      "downloading report\n",
      "no report available for version 5\n",
      "downloading report\n",
      "no report available for version 7\n",
      "downloading report\n",
      "no report available for version 9\n",
      "downloading report\n",
      "no report available for version 11\n",
      "downloading report\n",
      "downloading report\n",
      "no report available for version 14\n",
      "downloading report\n",
      "no report available for version 16\n",
      "downloading report\n",
      "no report available for version 18\n",
      "no report available for version 19\n",
      "downloading report\n",
      "no report available for version 21\n",
      "no report available for version 22\n",
      "downloading report\n",
      "no report available for version 24\n",
      "downloading report\n",
      "downloading report\n",
      "no report available for version 27\n",
      "downloading report\n",
      "no report available for version 29\n",
      "downloading report\n",
      "no report available for version 31\n",
      "downloading report\n",
      "no report available for version 33\n",
      "downloading report\n",
      "no report available for version 35\n",
      "no report available for version 36\n",
      "downloading report\n",
      "no report available for version 38\n",
      "downloading report\n",
      "no report available for version 40\n",
      "no report available for version 41\n",
      "downloading report\n",
      "no report available for version 43\n",
      "downloading report\n",
      "no report available for version 45\n",
      "downloading report\n",
      "no report available for version 47\n",
      "no report available for version 48\n",
      "downloading report\n",
      "downloading report\n",
      "fetching forecast\n",
      "forecast downloaded\n",
      "         DATE  TMAX  TMIN  PRCP  AWND  WDF2  WSF2  year  forecasted_TMAX\n",
      "21 2026-01-15    83    53   0.0   5.4   270    13  2026             81.0\n",
      "0  2026-01-14    80    50   0.0   4.5   260    13  2026              NaN\n",
      "1  2026-01-13    79    47   0.0   3.5   270    13  2026              NaN\n",
      "2  2026-01-12    72    48   0.0   3.2   110    10  2026              NaN\n",
      "3  2026-01-11    75    45   0.0   5.1   270    13  2026              NaN\n",
      "4  2026-01-10    70    42   0.0   3.4    40    10  2026              NaN\n",
      "5  2026-01-09    63    41   0.0   4.5   250     9  2026              NaN\n",
      "6  2026-01-08    62    48   0.0   9.0   300    28  2026              NaN\n"
     ]
    }
   ],
   "source": [
    "df = merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909dcb47-b6f1-4d6c-b5c7-6f5c58f8973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22 entries, 21 to 20\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   DATE             22 non-null     datetime64[ns]\n",
      " 1   TMAX             22 non-null     int64         \n",
      " 2   TMIN             22 non-null     int64         \n",
      " 3   PRCP             21 non-null     float64       \n",
      " 4   AWND             22 non-null     float64       \n",
      " 5   WDF2             22 non-null     int64         \n",
      " 6   WSF2             22 non-null     int64         \n",
      " 7   year             22 non-null     int32         \n",
      " 8   forecasted_TMAX  1 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1), int64(4)\n",
      "memory usage: 1.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede7e566-dac1-47e8-95bc-ad67bf80e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no report available for version 1\n",
      "downloading report\n",
      "no report available for version 3\n",
      "downloading report\n",
      "no report available for version 5\n",
      "downloading report\n",
      "no report available for version 7\n",
      "downloading report\n",
      "no report available for version 9\n",
      "downloading report\n",
      "no report available for version 11\n",
      "downloading report\n",
      "downloading report\n",
      "no report available for version 14\n",
      "downloading report\n",
      "no report available for version 16\n",
      "downloading report\n",
      "no report available for version 18\n",
      "no report available for version 19\n",
      "downloading report\n",
      "no report available for version 21\n",
      "no report available for version 22\n",
      "downloading report\n",
      "no report available for version 24\n",
      "downloading report\n",
      "downloading report\n",
      "no report available for version 27\n",
      "downloading report\n",
      "no report available for version 29\n",
      "downloading report\n",
      "no report available for version 31\n",
      "downloading report\n",
      "no report available for version 33\n",
      "downloading report\n",
      "no report available for version 35\n",
      "no report available for version 36\n",
      "downloading report\n",
      "no report available for version 38\n",
      "downloading report\n",
      "no report available for version 40\n",
      "no report available for version 41\n",
      "downloading report\n",
      "no report available for version 43\n",
      "downloading report\n",
      "no report available for version 45\n",
      "downloading report\n",
      "no report available for version 47\n",
      "no report available for version 48\n",
      "downloading report\n",
      "downloading report\n",
      "fetching forecast\n",
      "forecast downloaded\n",
      "         DATE  TMAX  TMIN  PRCP  AWND  WDF2  WSF2  year  forecasted_TMAX\n",
      "21 2026-01-15    83    53   0.0   5.4   270    13  2026             81.0\n",
      "0  2026-01-14    80    50   0.0   4.5   260    13  2026              NaN\n",
      "1  2026-01-13    79    47   0.0   3.5   270    13  2026              NaN\n",
      "2  2026-01-12    72    48   0.0   3.2   110    10  2026              NaN\n",
      "3  2026-01-11    75    45   0.0   5.1   270    13  2026              NaN\n",
      "4  2026-01-10    70    42   0.0   3.4    40    10  2026              NaN\n",
      "5  2026-01-09    63    41   0.0   4.5   250     9  2026              NaN\n",
      "6  2026-01-08    62    48   0.0   9.0   300    28  2026              NaN\n",
      "starting feature engineering\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[22:55:08] /Users/runner/work/xgboost/xgboost/src/common/io.cc:144: Opening /Users/giulioelmi/Desktop/kelshi_trading/inference/best1.1.json failed: No such file or directory\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000117088545 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x00000001171c7656 xgboost::common::LoadSequentialFile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>) + 790\n  [bt] (2) 3   libxgboost.dylib                    0x000000011715b36b XGBoosterLoadModel::$_0::operator()() const + 171\n  [bt] (3) 4   libxgboost.dylib                    0x000000011715ad10 XGBoosterLoadModel + 1040\n  [bt] (4) 5   libffi.8.dylib                      0x0000000108b52972 ffi_call_unix64 + 82\n  [bt] (5) 6   ???                                 0x00007ff7b8b8b7d0 0x0 + 140701932763088\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m latest_prediction = \u001b[43mmake_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_engineering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m latest_prediction\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mmake_prediction\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      4\u001b[39m inference_df = df\n\u001b[32m      5\u001b[39m model = XGBRegressor()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/giulioelmi/Desktop/kelshi_trading/inference/best1.1.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m pred_error = \u001b[38;5;28mfloat\u001b[39m(model.predict(inference_df)[\u001b[32m0\u001b[39m])\n\u001b[32m      8\u001b[39m forecast = df[\u001b[33m\"\u001b[39m\u001b[33mforecasted_TMAX\u001b[39m\u001b[33m\"\u001b[39m].iloc[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kelshi_trading/.venv/lib/python3.13/site-packages/xgboost/sklearn.py:1125\u001b[39m, in \u001b[36mXGBModel.load_model\u001b[39m\u001b[34m(self, fname)\u001b[39m\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__sklearn_is_fitted__():\n\u001b[32m   1124\u001b[39m     \u001b[38;5;28mself\u001b[39m._Booster = Booster({\u001b[33m\"\u001b[39m\u001b[33mn_jobs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.n_jobs})\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1127\u001b[39m meta_str = \u001b[38;5;28mself\u001b[39m.get_booster().attr(\u001b[33m\"\u001b[39m\u001b[33mscikit_learn\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meta_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kelshi_trading/.venv/lib/python3.13/site-packages/xgboost/core.py:3052\u001b[39m, in \u001b[36mBooster.load_model\u001b[39m\u001b[34m(self, fname)\u001b[39m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_pathlike(fname):\n\u001b[32m   3050\u001b[39m     \u001b[38;5;66;03m# assume file name, cannot use os.path.exist to check, file can be from URL.\u001b[39;00m\n\u001b[32m   3051\u001b[39m     fname = os.fspath(os.path.expanduser(fname))\n\u001b[32m-> \u001b[39m\u001b[32m3052\u001b[39m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterLoadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mbytearray\u001b[39m):\n\u001b[32m   3054\u001b[39m     buf = fname\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/kelshi_trading/.venv/lib/python3.13/site-packages/xgboost/core.py:323\u001b[39m, in \u001b[36m_check_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[31mXGBoostError\u001b[39m: [22:55:08] /Users/runner/work/xgboost/xgboost/src/common/io.cc:144: Opening /Users/giulioelmi/Desktop/kelshi_trading/inference/best1.1.json failed: No such file or directory\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000117088545 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x00000001171c7656 xgboost::common::LoadSequentialFile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>) + 790\n  [bt] (2) 3   libxgboost.dylib                    0x000000011715b36b XGBoosterLoadModel::$_0::operator()() const + 171\n  [bt] (3) 4   libxgboost.dylib                    0x000000011715ad10 XGBoosterLoadModel + 1040\n  [bt] (4) 5   libffi.8.dylib                      0x0000000108b52972 ffi_call_unix64 + 82\n  [bt] (5) 6   ???                                 0x00007ff7b8b8b7d0 0x0 + 140701932763088\n\n"
     ]
    }
   ],
   "source": [
    "latest_prediction = make_prediction(feature_engineering(merge_data()))\n",
    "latest_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238bc9e6-89d3-4884-945e-1cacfa69ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all markets for the KXHIGHNY series\n",
    "from datetime import datetime\n",
    "ticker = \"KXHIGHLAX\"\n",
    "def get_markets_data(ticker):\n",
    "    markets_url = f\"https://api.elections.kalshi.com/trade-api/v2/markets?series_ticker={ticker}&status=open\"\n",
    "    markets_response = requests.get(markets_url)\n",
    "    markets_data = markets_response.json()\n",
    "    rows = []\n",
    "    for market in markets_data['markets']:\n",
    "        ticker = market.get(\"event_ticker\")\n",
    "        dt = ticker.split(\"-\")[1]\n",
    "        date = datetime.strptime(\"20\" + dt, \"%Y%b%d\").date()\n",
    "        floor = market.get(\"floor_strike\")\n",
    "        cap = market.get(\"cap_strike\")\n",
    "        no_ask = market.get(\"no_ask\")\n",
    "        yes_ask = market.get(\"yes_ask\")\n",
    "        data = {\"date\": date, \"ticker\": ticker, \"floor\": floor, \"cap\": cap, \"no_ask\": no_ask, \"yes_ask\": yes_ask}\n",
    "        rows.append(data)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    for c in [\"floor\", \"cap\", \"no_ask\", \"yes_ask\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    #print(json.dumps(markets_data, indent=4))\n",
    "    tomorrow = pd.Timestamp.today().normalize() + pd.Timedelta(days=1)\n",
    "    df = df[df[\"date\"] == tomorrow]\n",
    "    df = df.sort_values(by = \"cap\")\n",
    "    return df\n",
    "    \n",
    "market_data = get_markets_data(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fcab366-8714-4a53-9f92-926f2779ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>floor</th>\n",
       "      <th>cap</th>\n",
       "      <th>no_ask</th>\n",
       "      <th>yes_ask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>KXHIGHLAX-26JAN16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>KXHIGHLAX-26JAN16</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>KXHIGHLAX-26JAN16</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>KXHIGHLAX-26JAN16</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>KXHIGHLAX-26JAN16</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date             ticker  floor   cap  no_ask  yes_ask\n",
       "1 2026-01-16  KXHIGHLAX-26JAN16    NaN  74.0      82       19\n",
       "5 2026-01-16  KXHIGHLAX-26JAN16   74.0  75.0      77       24\n",
       "4 2026-01-16  KXHIGHLAX-26JAN16   76.0  77.0      72       31\n",
       "3 2026-01-16  KXHIGHLAX-26JAN16   78.0  79.0      80       22\n",
       "2 2026-01-16  KXHIGHLAX-26JAN16   80.0  81.0      89       14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b70c37-9be4-489c-a505-663b0fc38b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def max_prices_df(markets: pd.DataFrame, mu: float, sigma: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each Kalshi contract row, compute:\n",
    "      - p_yes: model-implied probability that YES settles to 1\n",
    "      - max_yes / max_no: maximum price (in cents) you're willing to pay for YES/NO\n",
    "      - edges vs current asks (optional but useful)\n",
    "\n",
    "    Assumptions about contract encoding:\n",
    "      - floor & cap present  -> bucket: floor <= T < cap\n",
    "      - floor present only   -> unilateral: T >= floor\n",
    "      - cap present only     -> unilateral: T < cap\n",
    "\n",
    "    Prices in the input are assumed to be in cents (0..100).\n",
    "    \"\"\"\n",
    "\n",
    "    def norm_cdf(x: float) -> float:\n",
    "        # Standard normal CDF using erf (no scipy dependency)\n",
    "        return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "    def prob_yes(row) -> float:\n",
    "        floor = row.get(\"floor\")\n",
    "        cap = row.get(\"cap\")\n",
    "\n",
    "        has_floor = pd.notna(floor)\n",
    "        has_cap = pd.notna(cap)\n",
    "\n",
    "        if has_floor and has_cap:\n",
    "            # P(floor <= T < cap)\n",
    "            z_u = (cap - mu) / sigma\n",
    "            z_l = (floor - mu) / sigma\n",
    "            p = norm_cdf(z_u) - norm_cdf(z_l)\n",
    "        elif has_floor and not has_cap:\n",
    "            # P(T >= floor)\n",
    "            z = (floor - mu) / sigma\n",
    "            p = 1.0 - norm_cdf(z)\n",
    "        elif has_cap and not has_floor:\n",
    "            # P(T < cap)\n",
    "            z = (cap - mu) / sigma\n",
    "            p = norm_cdf(z)\n",
    "        else:\n",
    "            # If both missing, cannot interpret the contract\n",
    "            p = float(\"nan\")\n",
    "\n",
    "    out = markets.copy()\n",
    "\n",
    "    out[\"p_yes\"] = out.apply(prob_yes, axis=1)\n",
    "    out[\"p_no\"] = 1.0 - out[\"p_yes\"]\n",
    "\n",
    "    # Maximum you're willing to pay (in cents)\n",
    "    out[\"max_yes_cents\"] = (100.0 * out[\"p_yes\"]).round(2)\n",
    "    out[\"max_no_cents\"] = (100.0 * out[\"p_no\"]).round(2)\n",
    "\n",
    "    # Compare to current asks (also in cents)\n",
    "    if \"yes_ask\" in out.columns:\n",
    "        out[\"edge_yes_cents\"] = (out[\"max_yes_cents\"] - out[\"yes_ask\"]).round(2)\n",
    "    if \"no_ask\" in out.columns:\n",
    "        out[\"edge_no_cents\"] = (out[\"max_no_cents\"] - out[\"no_ask\"]).round(2)\n",
    "\n",
    "    # Handy boolean suggestions (strictly positive edge)\n",
    "    if \"yes_ask\" in out.columns:\n",
    "        out[\"buy_yes\"] = out[\"edge_yes_cents\"] > 0\n",
    "    if \"no_ask\" in out.columns:\n",
    "        out[\"buy_no\"] = out[\"edge_no_cents\"] > 0\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2b66a-a298-4d14-a664-1465289f4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is your Kalshi markets dataframe\n",
    "result = max_prices_df(get_markets_data(ticker), mu=66.48624873161316, sigma=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc6686-42a4-4d08-b2fc-f35e2113c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost, sklearn, sys\n",
    "print(sys.version)\n",
    "print(xgboost.__version__)\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e039b-f4ce-43ac-aa31-8283ded6ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(market_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800be03-fa62-4b3d-895c-e9619f07b8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
